\documentclass{article}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{url}
\usepackage{hhline}
\usepackage{float}
\usepackage{subcaption}
\usepackage[margin=1in]{geometry}

\newcommand*\rot{\rotatebox{90}}

\begin{document}

\title{A Comparison of String Search Algorithms for Deep Packet Inspection}
\author{Kieran Hunt}

\maketitle

\begin{abstract}
Contemporary deep packet inspection systems often rely on custom hardware or entrenched ideas about the string search algorithms used. These algorithms have mathematically provable time or space complexities however not much is empirically known about their performance on real-world packet datasets. We felt that some string search algorithms could produce results that differed from their theoretical performance within the context of packet inspection. Furthermore, we sought to show that even algorithms with similar theoretical performances could produce differing practical results. Our approach was to reimplement a variety of the established string search algorithms and run them through a diverse set of tests with both real-world and constructed datasets. Our tests found that the Bloom filter was the fastest overall, Rabin-Karp was the most memory efficient and that the Naïve algorithm was the slowest. Furthermore we found that, although the Bloom and Cuckoo filters have the same theoretical time complexity, the cuckoo filter was almost twice as slow as its counterpart. These findings help to show which algorithms perform best in practice and can help future algorithm designers to improve on the current approaches. In practice we show which algorithms a designer of a deep packet inspection system should consider implementing based on our findings.
\end{abstract}

\tableofcontents

\section{Introduction}
Deep packet inspection (DPI) forms part of the packet filtering that takes place on a computer network. For the general routing of a packet it is only necessary to look as far as the packet's headers. DPI takes the inspection further by closely examining the packet's payload data; its purpose is to detect data in a packet that is interesting to the network administrator. Generally, data that is interesting to the administrator is viruses, spam, incomplete or corrupted protocols, and obvious intrusions.

Deep packet inspection is very prevalent today. From Internet Service Providers (ISPs) to Corporate Networks. Packets are inspected for a plethora of reasons. 

Today, many approaches exist to perform deep packet inspection. These approaches can be broadly split into two categories: hardware and software. A hardware implementation generally requires the use of expensive and custom systems such as Field Programmable Gate Arrays (FPGAs). Hardware is generally faster than software (should cite) but has slower compile times and does not scale as well. Software, like Bro\footnote{\url{https://www.bro.org/}} and Snort\footnote{\url{https://www.snort.org/}}, is generally run on commercial off-the-shelf (COTS) machines or on virtualised infrastructure. Owing to the fact that it is not tied to the underlying architecture, software implementations are able to easily scale both vertically (speed of the machines) and horizontally (number of machines) to match the needs of the network.

Bro and Snort are two platforms designed for network analysis.

Deep packet inspection is traditionally done within an intrusion detection system (IDS) and as such needs to be fast enough that it can at least match the speed of the network. Failing to at least match the network speed will result in a slowdown of traffic flowing into the network, the queuing of yet to be inspected packets and, if the situation does not improve in time, the eventual dropping of packets as the queue fills. This result is certainly undesired as it negatively impacts the quality of service (QOS) experienced by users on the network.  

Deep packet searching in general is very similar to searching through text. Packets contain a payload which is analogous to a body of text. Packet inspection differs from text searching in that searches through text are generally for a single or only a few terms at a time whilst in packet inspection scenarios the search terms can number in the thousands. 

\section{Algorithms} \label{algorithms}

The following section gives some information on the different algorithms used. 

\subsection{Na{\"i}ve} \label{sec:naive} \label{sec:naive}
In order to objectively compare algorithms we implemented a control algorithm. Named Na{\"i}ve, this\footnote{\url{https://github.com/KieranHunt/dpi_algorithms/blob/master/src/dpi_interface/naive.rs}} algorithm has a O(\(n^2\)) time efficiency. The algorithm simply tests every possible substring of the text against the search term. See Figure \ref{fig:naive} for an example.
\begin{figure}[h!bt]
  
  \centering
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/naive-1}
  \caption{The Na{\"i}ve algorithm compares the first letter of the search term to the first letter of the text.}
  \end{subfigure}
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/naive-2}
  \caption{Because the first letter of the search term did not match the first letter of the text, the Na{\"i}ve algorithm now compares the second letter of the text to the first letter of the search term.}
  \end{subfigure}
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/naive-3}
  \caption{After some iteration, the first letter of the search term is matched against the fifth letter of the text.}
  \end{subfigure}
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/naive-4}
  \caption{The next letter of the text does not match the second letter of the search term. A match is not declared.}
  \end{subfigure}
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/naive-5}
  \caption{As before letters from the search term match letters in the text. In this case the entirety of the search term was matched in the text and so a match is declared.}
  \end{subfigure}
  
  \caption{The process by which the Na{\"i}ve algorithm conducts its search}
  \label{fig:naive}
\end{figure}

\subsection{Aho-Corasick} \label{sec:aho-corasick}
This string search algorithm, originally proposed by \cite{Aho1975}, matches all search terms simultaneously.

The Aho-Corasick algorithm was designed as an improvement on the trie (or keyword tree). A trie works by constructing a tree where each edge is labeled by a character and each node is the concatenation of edges leading up to the node. Nodes are then labeled with the index of the corresponding search term. For the search terms: he, she, his, hers (\(P = \{he, she, his, hers\}\)); a trie can be constructed (See \ref{fig:trie}).

\begin{figure}[h!bt]
  \label{fig:trie}
  \centering
  \makeatletter
  \includegraphics[width=\textwidth]{images/trie.pdf}
  \caption{Trie (keyword tree) for the search terms \(P = \{he, she, his, hers\}\)}
\end{figure}

A lookup through a trie done by starting at the root, follow a path by matching the packet data against the edge labels for as long as possible. If the path leads to a node that is labeled: the string is a search term. If the path terminates at a node that does not have a label then no match is made. Lookups have \(O(nm)\) time complexity.

As stated, the Aho-Corasick algorithm is an extension of the trie. The algorithm extends the trie into an automaton. The following functions are defined to determine the subsequent action given the current node and character being inspected: goto, failure and output.

\subsubsection{The goto function} \label{goto-function}

Defined as \(g(q, a)\), the goto function gives the next state by taking the current state (or node) \(q\) and a matching character \(a\) as parameters. If an edge \((q, v)\) has the label \(a\) then the goto function is defined as \(g(q, a) = v\). \(g(0, a) = 0\) for any \(a\) that does not have an edge labeled out of the root node. For anything else \(g(q, a) =  \emptyset\). The goto function is represented as solid arrows in Figure \ref{fig:automaton}.

\subsubsection{The failure function} \label{failure-function}

The failure function, or \(f(q)\), defines the next state if no suitable state from the goto function has been found. In other words, when a mismatch occurs. The failure function finds the longest suffix of the label at \(q\) which is a prefix of a search term. The failure function is represented as dotted arrows in Figure \ref{fig:automaton}.

\subsubsection{The output function} \label{output-function}

The output function, \(out(q)\) defines all search terms that have been recognised when entering \(q\). The output function is represented as the text within the curly braces in Figure \ref{fig:automaton}.

\begin{figure}[h!bt]
  
  \centering
  \makeatletter
  \includegraphics[width=\textwidth]{images/ac-automaton}
  \caption{Aho-Corasick Automaton for \(P = \{he, she, his, hers\}\)}
  \label{fig:automaton}
\end{figure}

The algorithm has a proven linear time complexity proportional to the sum of the length of the packet, the search terms and the number of times a term is matched \citep{Aho1975}. Formally it has O(\(n + m + z\)) where \(n\) is the length of the packet payload, \(m\) is the length of the search terms and \(z\) is the number of times the pattern is matched.

With the small initial overhead encountered when constructing the automaton (computing the goto [see \ref{goto-function}] , failure [see \ref{failure-function}] and output [see \ref{output-function}] functions), the Aho-Corasick algorithm can shave off precious time by eliminating unnecessary work using the failure functions.

\subsection{Bitap} \label{sec:bitap}

Best known for its use in agrep \citep{Wu1992}\footnote{\url{https://github.com/Wikinaut/agrep/blob/master/bitap.c}}, the Bitap algorithm published by \cite{Baeza1992} is an approximate string matching algorithm. That is to say that for a given search term and substring of text, the Bitap algorithm can tell you if those elements are approximately equal. The algorithm's speed is due to its use of bitwise operations on precomputed bitmasks .

\subsection{Bloom} \label{sec:bloom}

A Bloom filter, first proposed by \cite{Bloom1970}, is a data-structure used to determine whether something is a member of a set. Traditionally Bloom filters and other hash table-based algorithms have been used in networking applications such as routing, shallow packet inspection and network monitoring \citep{Song2005}›. In the context of packet inspection a Bloom filter is used to see if a substring of the packet payload is a member of the set containing all search terms.

A bloom filter works by hashing each of the search terms a number of times, for each hash a bit is set in a corresponding bit vector. Lookup in a bloom filter involves hashing the string that you want to look up each time for each bit vector and checking to see if the bits are set. The price for efficient such efficient lookup is that a bloom filter can only tell you if a string in definitely not in the set. It can only say with a non-100 percent certainty if the string matches a search term.

\begin{figure}[h!bt]
  \label{bloom-1}
  \centering
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/bloom-1}
  \caption{The bloom filter initially starts with hash tables initialised to zero, one for each of the hash functions being used.}
  \end{subfigure}
\end{figure} 

\begin{figure}[h!bt]
  \ContinuedFloat  
  \label{bloom-2}
  \centering
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/bloom-2}
  \caption{The first search term is hashed by each of the hashing algorithms, for each algorithm a single value is returned. The place in the hash table corresponding to the value is set. Here 5 is set for Hash 1, 3 for Hash 2 and 9 for Hash 10.}
  \end{subfigure}
\end{figure}

\begin{figure}[h!bt]
  \ContinuedFloat  
  \label{bloom-3}
  \centering
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/bloom-3}
  \caption{A second search term is put through the three hashing functions. For this term Hash 1 gives the value of 7, Hash 2 gives 3 and Hash 3 gives 5. Note that Hash 2 has given the same values for both search terms.}
  \end{subfigure}
\end{figure}

\begin{figure}[h!bt]
  \ContinuedFloat  
  \label{bloom-4}
  \centering
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/bloom-4}
  \caption{When doing a lookup in a Bloom table, a similar approach is used to insertion. The term being looked up is hashed by the various hashing algorithms and the hash tables are check to see if the corresponding bits are set. Here the first two hash tables show that the bits are set but the last hash table does not find a match. No match is declared.}
  \end{subfigure}
\end{figure}

\begin{figure}[h!bt]
  \ContinuedFloat  
  \label{bloom-5}
  \centering
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/bloom-5}
  \caption{Another being of text is being evaluated. Here the text is put through the same three hashing algorithms and for each one a corresponding entry in the hash table is found. The Bloom filter declares this a likely match. The careful reader may notice that this is, in fact, not a match. Figures \ref{bloom-2} and \ref{bloom-3} show each term being added to the Bloom filter and the results of this search do not match the insertions.}
  \end{subfigure}
\end{figure}

\begin{figure}[h!bt]
  \ContinuedFloat  
  \label{bloom-6}
  \centering
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/bloom-6}
  \caption{Another piece of text is put through the bloom filter with matches again appearing. These matches are not false positives as they correspond to the initially placed bit during the insertion phase.}
  \end{subfigure}
  \caption{The process of inserting into and doing a lookup on a Bloom filter.}
\end{figure}

\subsection{Boyer-Moore} \label{sec:boyer-moore}

The Boyer-Moore algorithm \citep{Boyer1977} is an improved version of the Na{\"i}ve algorithm. It too uses a sliding window to compare the search string with substrings in the search text. Boyer-Moore's improvement on the Na{\"i}ve algorithm involves a pre-processing step whereby the algorithm determines certain ways that it can jump over text.

In the Na{\"i}ve algorithm, if during the matching of a word it fails halfway through, the algorithm simply starts at the next character. The Boyer-Moore uses its pre-processing step to determine if and how far along in the text the algorithm can jump. Thus making fewer comparisons and increasing the overall speed.

The Boyer-Moore algorithm works by comparing text from the rear to the front of the search pattern. If the character in the text does not match any character in the search pattern then the pattern can jump the length of the pattern forward. If the character is found somewhere within the search string then the pattern is shifted to where the characters line up and the process is then repeated.

\subsection{Horspool} \label{sec:horspool}
The Horspool algorithm \citep{Horspool1980} (also known as the Boyer-Moore-Horspool algorithm) is a string search algorithm which is extremely fast. It has a average time complexity of O(\(n\)) and a worst case complexity of O(\(mn\)) \citep{Horspool1980}.

The average time complexity is met when 

Like the Boyer-Moore algorithm \citep{Boyer1977} (See \ref{boyer-moore}), the Horspool algorithm has a preprocess step in which a table is created representing each symbol of the alphabet and where the algorithm can skip to.

The algorithm encounters its worst case time complexity behaviour when the search term very closely matches the many substrings in the text being searched through. 

\subsection{Rabin-Karp} \label{sec:rabin-karp}

The Rabin-Karp algorithm \citep{Karp1987} is very similar to the Na{\"i}ve algorithm (See \ref{sec:naive}). It too compares substrings of the text to the search terms. The Rabin-Karp algorithm does, however, use hashing to faster compare search terms to the text. Rabin-Karp is well suited to searching for many search terms at the same time by simply taking an initial hash of the search terms and then doing multiple comparisons against the hashes of the substring of the text.

\subsection{Knuth-Morris-Pratt} \label{sec:knuth-morris-pratt}

The Knuth-Morris-Pratt (KMP) algorithm \cite{Knuth1977} is too an extension the the Na{\"i}ve algorithm (See \ref{sec:naive}). The KMP algorithm starts by comparing the each character of both the search string and the text being searched through. If a match is found the second character of both the search string and text are compared. Each successive character is compared. If the end of the search term is reached then a match is declared. The power of the KMP algorithm is apparent when only part of the search term is matched. By keeping a record of the previous comparisons, if the algorithm has noted that the start of the pattern has occurred elsewhere then a jump to that place can be made without the interim comparisons.

\begin{figure}[h!bt]
  
  \centering
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/knuth-morris-pratt-1}
  \caption{The KMP algorithm compares the first letter of the search string with the first letter of the text. No match is found.}
  \end{subfigure}
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/knuth-morris-pratt-2}
  \caption{The algorithm moved on to the second letter of the text and compares it with the first letter of the search term. No match is found.}
  \end{subfigure}
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/knuth-morris-pratt-3}
  \caption{Now the KMP algorithm compares the first letter of the search string with the third letter of the text. A match is found. The fourth and fifth letters of the text are compared with the second and third of the search term and they too match. Finally the the fourth letter of the search term is compared with the }
  \end{subfigure}
  
  \begin{subfigure}{\textwidth}
  \makeatletter
  \includegraphics[width=\textwidth]{images/knuth-morris-pratt-4}
  \caption{}
  \end{subfigure}

  
  \caption{The KMP algorithm performing a search for the term ``oden" in the string ``Rhodes rhodent"}
  \label{fig:knuth-morris-pratt}
\end{figure}

\subsection{Summary}

\begin{table}[hbt]
  \centering
  \begin{tabular}{r|cccccccccc}
    & Aho-Corasick & Bitap & Bloom & Boyer-Moore & Horspool & Knuth-Morris-Pratt & Na{\"i}ve & Rabin-Karp\\
    \hline
    Time & O(\(m + n + o\)) & O(\(mn\)) & O(\(n^2\)) & O(\(mn\)) & O(\(n\)) & O(\(k\)) & O(\(n^2\)) & O(\(n + m\)) \\
    Space & O(\(m\)) & O(\(m\)) & O(\(\)) & O(\(m + ?\)) & O(\(alphabet\)) & O(\(m\)) & N/A & O(\(p\))
  \end{tabular}
  \caption{Average algorithm time and space complexity}
\end{table}


\section{Testing Environment}	
Give a run-down of the system used.

The Rust language was used to implement all of the search algorithms. Rust was selected because it is fast and safe. Both  qualities are important in a real-time packet inspection scenarios. For interacting with both packet captures and live capture handles we used the Rust pcap\footnote{\url{https://github.com/ebfull/pcap}} library. This library provides a wrapper around libpcap\footnote{\url{http://www.tcpdump.org/}}. Through pcap, we are able to easily retrieve the packet data which can in turn be run through the various algorithms (See part \ref{algorithms}).

Each algorithm was implemented in Rust. All but the Bloom\footnote{\url{https://github.com/nicklan/bloom-rs}} \cite{Bloom1970} and Cuckoo\footnote{\url{https://github.com/seiflotfy/rust-cuckoofilter}} \cite{Fan2014} filters were were implemented by the authors.

Talk about the pcap format.

The data used in the tests was real-world packet data collected the DNS servers of local schools. The libpcap library, in conjunction with tcpdump was used to collect and save the packet information. The total number of captured packets was culled to a reasonable one million packets to allow for reasonable processing and interpretation times.

Each algorithm was separately run over the dataset for a variety of search terms.

Search terms: google, amazonaws.com

\begin{comment}
    grep -ao "amazonaws.com" datasetA.cap | wc -w
    grep -ao "google" datasetA.cap | wc -w
    
    ---------------------------------------------
    
    #!/bin/bash

    for i in $(eval echo "{1..${#2}}")
    do
        echo ${2:0:i}
        grep -ao ${2:0:i} $1 | wc -w
    done

    for i in $(eval echo "{${#2}..1}")
    do
        echo ${2:i-1:${#2}}
        grep -ao ${2:i-1:${#2}} $1 | wc -w
    done
    
\end{comment}
In dataset A, ``google" occurs 15223 times whilst ``amazonaws.com" occurs 6389 times.

\begin{table}[hbt]
  \centering
  \begin{tabular}{l|l|r||l|r}
    \multicolumn{2}{c}{``amazonaws.com"} & \multicolumn{2}{c}{``google"} \\
    Index & Prefix & Suffix & Prefix & Suffix \\
    \hline
    1. & a  & m  & g  & e \\
    2. & am  & om  & go  & le \\
    3. & ama  & com  & goo  & gle \\
    4. & amaz  & .com  & goog  & ogle \\
    5. & amazo  & s.com  & googl  & oogle \\
    6. & amazon  & ws.com  & google  & google \\
    7. & amazona  & aws.com  &  & \\
    8. & amazonaw  & naws.com  &  & \\
    9. & amazonaws  & onaws.com  &  & \\
    10. & amazonaws.  & zonaws.com  &  & \\
    11. & amazonaws.c  & azonaws.com  &  & \\
    12. & amazonaws.co  & mazonaws.com  &  & \\
    13. & amazonaws.com  & amazonaws.com  &  & 
  \end{tabular}
  \caption{}
\end{table}

\begin{table}[hbt]
  \centering
  \begin{tabular}{ll|rl||ll|rl}
    \multicolumn{4}{c}{``amazonaws.com"} & \multicolumn{4}{c}{``google"} \\
    Prefix & Count & Suffix & Count & Prefix & Count & Suffix & Count \\
    \hline
    a & 2783497 & m & 812339 & g & 465303 & e & 1061226\\
    am & 101726 & om & 290968 & go & 19007 & le & 92113\\
    ama & 55808 & com & 266672 & goo & 15456 & gle & 15432\\
    amaz & 9111 & .com & 266645 & goog & 15231 & ogle & 15223\\
    amazo & 9094 & s.com & 25810 & googl & 15223 & oogle & 15223\\
    amazon & 9094 & ws.com & 6980 & google & 15223 & google & 15223\\
    amazona & 7285 & aws.com & 6389 & & & &\\
    amazonaw & 7285 & naws.com & 6389 & & & &\\
    amazonaws & 7285 & onaws.com & 6389 & & & &\\
    amazonaws. & 6389 & zonaws.com & 6389 & & & &\\
    amazonaws.c & 6389 & azonaws.com & 6389 & & & &\\
    amazonaws.co & 6389 & mazonaws.com & 6389 & & & &\\
    amazonaws.com & 6389 & amazonaws.com & 6389 & & & &
  \end{tabular}
  \caption{Search term prefix and suffix frequency for the packet dataset: Dataset A.}
\end{table}

\begin{table}[hbt]
  \centering
  \begin{tabular}{ll|rl||ll|rl}
    \multicolumn{4}{c}{``amazonaws.com"} & \multicolumn{4}{c}{``google"} \\
    Prefix & Count & Suffix & Count & Prefix & Count & Suffix & Count \\
    \hline
    a & 2783497 & m & 812339 & g & 465303 & e & 1061226\\
    am & 101726 & om & 290968 & go & 19007 & le & 92113\\
    ama & 55808 & com & 266672 & goo & 15456 & gle & 15432\\
    amaz & 9111 & .com & 266645 & goog & 15231 & ogle & 15223\\
    amazo & 9094 & s.com & 25810 & googl & 15223 & oogle & 15223\\
    amazon & 9094 & ws.com & 6980 & google & 15223 & google & 15223\\
    amazona & 7285 & aws.com & 6389 & & & &\\
    amazonaw & 7285 & naws.com & 6389 & & & &\\
    amazonaws & 7285 & onaws.com & 6389 & & & &\\
    amazonaws. & 6389 & zonaws.com & 6389 & & & &\\
    amazonaws.c & 6389 & azonaws.com & 6389 & & & &\\
    amazonaws.co & 6389 & mazonaws.com & 6389 & & & &\\
    amazonaws.com & 6389 & amazonaws.com & 6389 & & & &
  \end{tabular}
  \caption{}
\end{table}


Books: Alices-Adventures-in-Wonderland.txt, Pride-and-Prejudice.txt, The-Prince.txt, Bird-Watching.txt, The-Adventures-of-Sherlock-Holmes.txt, The-Yellow-Wallpaper.txt, Frankenstein-or-the-Modern-Prometheus.txt, and The-Adventures-of-Tom-Sawyer-Complete.txt.

\begin{comment}
 To get the size of each file:
    $ find . -name '*.cap' | xargs du -h
 To get the number of packets in each file:
    $ find . -name '*.pcap' | xargs wc
 The previous one may be incorrect.
\end{comment}

\section{Results} \label{sec:results}

\begin{table}[hbt]
  \centering
  \begin{tabular}{ccccccc}
    Bitap & Bloom & Boyer-Moore & Horspool & Knuth-Morris Pratt & Na{\"i}ve & Rabin-Karp \\
    \hline
    48.6 & 51190 & 5.226 & 5.041 & 12.42 & 15.91 & 1701.0
  \end{tabular}
  \caption{Mean packet processing times for the various algorithms with the search term: ``amazonaws.com"}
  \label{table:packet-amazonaws-mean}
\end{table}

\begin{table}[hbt]
  \centering
  \begin{tabular}{ccccccc}
    Bitap & Bloom & Boyer-Moore & Horspool & Knuth-Morris Pratt & Na{\"i}ve & Rabin-Karp \\
    \hline
    71.51 & 48300 & 5.642 & 5.804 & 11.48 & 15.95 & 1720.0
  \end{tabular}
  \caption{Mean packet processing times for the various algorithms with the search term: ``google"}
  \label{table:packet-google-mean}
\end{table}

\begin{table}[hbt]
  \centering
  \begin{tabular}{l|cc}
    Book & Short Name & Size\\
    \hline
    Alices Adventures in Wonderland & AAW & 269K \\
    Bird Watching & BW & 653K \\
    Frankenstein or the Modern Prometheus & FMP & 525K \\
    Pride and Prejudice & PP & 780K \\
    The Adventures of Sherlock Holmes & ASH & 653K \\
    The Adventures of Tom Sawyer Complete & ATSC & 525K \\
    The Yellow Wallpaper & YW & 58K
  \end{tabular}
  \caption{}
\end{table}


\begin{table}[h!bt]
  \centering
  \begin{tabular}{r|ccccccc}
    & \rot{AAW} & \rot{BW} & \rot{FMP} &  \rot{PP} & \rot{ASH} & \rot{ATSC} & \rot{YW}\\
    \hline
    Bitap & 657900 & 656200 & 657200 & 659000 & 654900 & 659500 & 656600 \\
    Boyer-Moore & 12700 & 13470 & 13100 & 13660 & 13410 & 13120 & 12580 \\
    Horspool & 19510 & 20730 & 20250 & 20990 & 20610 & 20080 & 19120 \\
    Knuth-Morris-Pratt & 55150 & 55970 & 55540 & 55930 & 55730 & 55940 & 55150 \\
    Na{\"i}ve & 124400 & 125200 & 124500 & 124900 & 124900 & 125100 & 124200 \\
    Rabin-Karp & 17840000 & 17840000 & 17820000 & 17840000 &  17860000 & 17850000 & 17810000
  \end{tabular}
  \caption{Mean processing time of DPI when inspecting plain text for the term ``google"}
  \label{table:mean-books-google}
\end{table}

\begin{table}[h!bt]
  \centering
  \begin{tabular}{r|ccccccc}
    & \rot{AAW} & \rot{BW} & \rot{FMP} &  \rot{PP} & \rot{ASH} & \rot{ATSC} & \rot{YW}\\
    \hline
    Bitap & 1262000 & 1260000 & 1258000 & 1259000 & 1260000 & 1260000 & 1259000 \\
    Boyer-Moore & 5598 & 6120 & 5951 & 6300 & 6129 & 5927 & 5468 \\
    Horspool & 8502 & 9392 & 9065 & 9620 & 9395 & 9035 & 8321 \\
    Knuth-Morris-Pratt & 51980 & 54180 & 53420 & 54610 & 54160 & 53260 & 51450 \\
    Na{\"i}ve & 115200 & 118000 & 117200 & 118800 & 118000 & 116900 & 114500 \\
    Rabin-Karp & 426800 & 427400 & 427000 & 427200 & 427100 & 427200 & 426200
  \end{tabular}
  \caption{Mean processing time of DPI when inspecting plain text for the term ``amazonaws.com"}
  \label{table:mean-books-amazonaws}
\end{table}

\section{Analysis}

The results (section \ref{sec:results}) of the testing have proven to be quite interesting. From tables \ref{table:packet-amazonaws-mean} and \ref{table:packet-google-mean} we are able to fairly easily see which algorithms are the most performant. By comparing the mean packet processing times against each other we can arrange the algorithms by speed. Table \ref{table:ranked-mean-packet-processing-time} shows that, from the test results, the Horspool (subsection \ref{sec:horspool}) and Boyer-Moore

\begin{table}[hbt]
  \centering
  \begin{tabular}{c|cc}
    Rank & Algorithm\\
    \hline
    1 & Horspool \\
      & Boyer-Moore \\
    3 & Knuth-Morris-Pratt \\
    4 & Na{\"i}ve \\
    5 & Bitap \\
    6 & Rabin-Karp \\
    7 & Bitap 
  \end{tabular}
  \caption{Algorithms ranked by their mean packet processing speeds.}
  \label{table:ranked-mean-packet-processing-time}
\end{table}


\begin{figure}[h!bt]
  \centering
  \includegraphics[width=\textwidth]{graphs/cum_sum_packets_google.png}
  \caption{Cumulative sum of processing times of packets in Dataset A for the term ``google"}
\end{figure}

\begin{figure}[h!bt]
  \centering
  \includegraphics[width=\textwidth]{graphs/cum_sum_packets_amazonaws-com.png}
  \caption{Cumulative sum of processing times of packets in Dataset A for the term ``amazonaws.com"}
\end{figure}

\begin{figure}[hbt]
  \centering
  \includegraphics[width=\textwidth]{graphs/term_length_compare-bitap.png}
  \caption{}
\end{figure}

\section{Conclusion}
Talk about going forward. Future work.
\nocite{*}


\bibliographystyle{apalike}
\bibliography{bibliography}

\end{document}