\documentclass{article}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{comment}

\begin{document}

\title{A Comparison of String Search Algorithms for Deep Packet Inspection}
\author{Kieran Hunt}

\maketitle

\begin{abstract}
Contemporary deep packet inspection systems often rely on custom hardware or entrenched ideas about the string search algorithms used. These algorithms have mathematically provable time or space complexities however not much is empirically known about their performance on real-world packet datasets. We felt that some string search algorithms could produce results that differed from their theoretical performance within the context of packet inspection. Furthermore, we sought to show that even algorithms with similar theoretical performances could produce differing practical results. Our approach was to reimplement a variety of the established string search algorithms and run them through a diverse set of tests with both real-world and constructed datasets. Our tests found that the Bloom filter was the fastest overall, Rabin-Karp was the most memory efficient and that the Na√Øve algorithm was the slowest. Furthermore we found that, although the Bloom and Cuckoo filters have the same theoretical time complexity, the cuckoo filter was almost twice as slow as its counterpart. These findings help to show which algorithms perform best in practice and can help future algorithm designers to improve on the current approaches. In practice we show which algorithms a designer of a deep packet inspection system should consider implementing based on our findings.
\end{abstract}

\section{Introduction}
Deep packet inspection (DPI) forms part of the packet filtering that takes place on a computer network. For the general routing of a packet it is only necessary to look as far as the packet's headers. DPI takes the inspection further by closely examining the packet's payload data; its purpose is to detect data in a packet that is interesting to the network administrator. Generally, data that is interesting to the administrator is viruses, spam, incomplete or corrupted protocols, and obvious intrusions.

Deep packet inspection is very prevalent today. From Internet Service Providers (ISP) to Corporate Networks. Packets are inspected for a plethora of reasons. 

Today, many approaches exist to perform deep packet inspection. The approaches can be split into two categories: hardware and software. A hardware implementation generally requires the use of expensive and custom systems such as Field Programmable Gate Arrays (FPGAs). Hardware is generally faster than software (should cite) but has slower compile times and does not scale as well. Software, like Bro and Snort, is generally run on Commercial off-the-shelf (COTS) machines or on virtualised infrastructure. Because it is not limited by the underlying hardware, the software implementations are able to scale both up and down to match the needs of the network.

Bro, Snort and others.

Speed requirements. Be at or above the network speed.

Talk about packet inspection with respect to string search. Compare searching through a book to searching through a packet.

\section{Algorithms}

A bit about each of the algorithms. Their time and space complexities. Talk about each of their strengths a weaknesses. Try to guess which might be good at DPI.

Talk about why we chose those algorithms. Talk about any that we didn't choose.

\subsection{Na{\"i}ve}
\subsection{Aho-Corasick}
\cite{Aho1975}
\subsection{Bitap}
\cite{Baeza1992}
\subsection{Bloom}
\cite{Bloom1970}
\subsection{Boyer-Moore}
\cite{Boyer1977}
\subsection{Cuckoo}
\cite{Fan2014}
\subsection{Horspool}
\cite{Horspool1980}
\subsection{Rabin-Karp}
\cite{Karp1987}
\subsection{Knuth-Morris-Pratt}
\cite{Knuth1977}

\section{Testing Environment}	
Give a run-down of the system used.

Talk about rust

Talk about implementing the algorithms in Rust.

Talk about what tests were run. What was measured.

The data used in the tests was real-world packet data collected from Rhodes University ('s proxies? firewalls?). Rhodes University actively collects and records the packets into and out of its network. The data collected is grouped by month. Our dataset spanned from September 2013 to July 2015. Because of the long period of time for which the packets were captured, the amassed capture file are very large.

\begin{comment}
 To get the size of each file:
    $ find . -name '*.cap' | xargs du -h
 To get the number of packets in each file:
    $ find . -name '*.pcap' | xargs wc
 The previous one may be incorrect.
\end{comment}

\newcommand*\rot{\rotatebox{90}}
\begin{table}[]
\centering
\caption{My caption}
\label{my-label}
\begin{tabular}{c|l|cc}
                 Year & Month & \#Packets & Size on Disk (GB) \\
                      \hline
\multirow{4}{*}{\rot{2013}} & September &  & 5 \\
                      & October &  &  23\\
                      & November &  & 20 \\
                      & December &  & 22 \\
                      \hline
\multirow{12}{*}{\rot{2014}} & January & & 30\\
                      & Febraury & & 30 \\
                      & March & & 51 \\
                      & April & & 30 \\
                      & May & & 0.34\\
                      & June & & 17\\
                      & July & & 23 \\
                      & August & & 15 \\
                      & September & & 24 \\
                      & October & & 28 \\
                      & November & & 30 \\
                      & December & & 12 \\
                      \hline
\multirow{7}{*}{\rot{2015}} & January & & 22 \\
                      & Febraury & & 25 \\
                      & March & & 29 \\
                      & April & & 13\\
                      & May & & 31 \\
                      & June & & 27 \\
                      & July & & 0.448 \\
\end{tabular}
\end{table}

\section{Results}
Have some tables of general speeds across the various algorithms/datasets. Same for memory.

\section{Analysis}
Compare results with each other.

Compare results against the theoretical outcomes.

\section{Conclusion}
Talk about going forward. Future work.
\nocite{*}


\bibliographystyle{apalike}
\bibliography{bibliography}

\end{document}